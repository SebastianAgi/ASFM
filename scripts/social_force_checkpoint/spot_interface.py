#!/usr/bin/env python3

import argparse
import logging
import math
import sys
import os
import subprocess
import time
import numpy as np

import bosdyn.client
import bosdyn.client.estop
import bosdyn.client.lease
import bosdyn.client.util
import bosdyn.geometry

from bosdyn.client import math_helpers
from bosdyn.client.image import ImageClient, build_image_request
from bosdyn.client.robot_command import RobotCommandBuilder, RobotCommandClient
from bosdyn.client.robot_state import RobotStateClient
from bosdyn.client.local_grid import LocalGridClient
from bosdyn.api import trajectory_pb2, basic_command_pb2, image_pb2, robot_state_pb2, local_grid_pb2, mobility_command_pb2

from bosdyn.client.frame_helpers import get_a_tform_b, get_vision_tform_body, get_odom_tform_body,\
    BODY_FRAME_NAME, GRAV_ALIGNED_BODY_FRAME_NAME, VISION_FRAME_NAME, ODOM_FRAME_NAME 

from bosdyn.client.async_tasks import AsyncPeriodicQuery, AsyncTasks
from google.protobuf.timestamp_pb2 import Timestamp

import google.protobuf.duration_pb2
from bosdyn.api import geometry_pb2
from bosdyn.client.math_helpers import SE2Pose, SE3Pose
from bosdyn.api import robot_command_pb2
from bosdyn.api.spot import robot_command_pb2 as spot_command_pb2



# ROS specific imports
import rospy
import diagnostic_msgs.msg
import geometry_msgs.msg
import std_msgs.msg
import sensor_msgs.msg
import visualization_msgs.msg
import spot_driver.msg
import spot_driver.srv

import tf2_ros 

from grid_utils import get_terrain_markers

front_image_sources = ['frontleft_fisheye_image', 'frontright_fisheye_image', 'frontleft_depth', 'frontright_depth']

class DefaultCameraInfo(sensor_msgs.msg.CameraInfo):
    """Blank class extending CameraInfo ROS topic that defaults most parameters"""
    def __init__(self):
        super().__init__()
        self.distortion_model = "plumb_bob"

        self.D.append(0)
        self.D.append(0)
        self.D.append(0)
        self.D.append(0)
        self.D.append(0)

        self.K[1] = 0
        self.K[3] = 0
        self.K[6] = 0
        self.K[7] = 0
        self.K[8] = 1

        self.R[0] = 1
        self.R[1] = 0
        self.R[2] = 0
        self.R[3] = 0
        self.R[4] = 1
        self.R[5] = 0
        self.R[6] = 0
        self.R[7] = 0
        self.R[8] = 1

        self.P[1] = 0
        self.P[3] = 0
        self.P[4] = 0
        self.P[7] = 0
        self.P[8] = 0
        self.P[9] = 0
        self.P[10] = 1
        self.P[11] = 0

class AsyncImageService(AsyncPeriodicQuery):
    """Class to get images at regular intervals.  get_image_from_sources_async query sent to the robot at every tick.  Callback registered to defined callback function.
        Attributes:
            client: The Client to a service on the robot
            logger: Logger object
            rate: Rate (Hz) to trigger the query
            callback: Callback function to call when the results of the query are available
    """
    def __init__(self, client, logger, rate, callback, image_requests):
        super(AsyncImageService, self).__init__("robot_image_service", client, logger,
                                           period_sec=1.0/max(rate, 1.0))
        self._callback = None
        if rate > 0.0:
            self._callback = callback
        self._image_requests = image_requests

    def _start_query(self):
        if self._callback:
            callback_future = self._client.get_image_async(self._image_requests)
            callback_future.add_done_callback(self._callback)
            return callback_future

class SpotInterface:
    '''Callbacks for an instance of a Spot robot'''

    # 0.6 s is the standard duration for cmds in boston dynamics Spot examples
    VELOCITY_CMD_DURATION = 0.6  # [seconds]
    TRAJECTORY_CMD_TIMEOUT = 20.0  # [seconds]
    x_goal_tolerance = 0.05 #[m]
    y_goal_tolerance = 0.05 #[m]
    angle_goal_tolerance = 0.075 #[rad]
    LOGGER = logging.getLogger()

    def __init__(self, config):
        # Ensure interface can ping Spot
        try:
            with open(os.devnull, 'wb') as devnull:
                resp = subprocess.check_call(['ping', '-c', '1', config.hostname], stdout=devnull, stderr=subprocess.STDOUT)
                if resp != 0:
                    print ("ERROR: Cannot detect a Spot with IP: {}.\nMake sure Spot is powered on and on the same network".format(config.hostname))
                    sys.exit()
        except:
            print("ERROR: Cannot detect a Spot with IP: {}.\nMake sure Spot is powered on and on the same network".format(config.hostname))
            sys.exit()

        # Set up SDK
        bosdyn.client.util.setup_logging(config.verbose)
        self.sdk = bosdyn.client.create_standard_sdk('spot_ros_interface_sdk')
        #self.sdk.load_app_token(config.app_token)

        # Create instance of a robot
        try:
            self.robot = self.sdk.create_robot(config.hostname)
            self.robot.authenticate(config.username, config.password)
            self.robot.time_sync.wait_for_sync()
        except bosdyn.client.RpcError as err:
            self.LOGGER.error("Failed to communicate with robot: %s", err)

        # Client to send cmds to Spot
        self.command_client = self.robot.ensure_client(
            RobotCommandClient.default_service_name)

        # Client to request images from Spot
        self.image_client = self.robot.ensure_client(
            ImageClient.default_service_name)

        self.image_source_names = [
            src.name for src in self.image_client.list_image_sources() if "image" in src.name
        ]

        self.depth_image_sources = [
            src.name for src in self.image_client.list_image_sources() if "depth" in src.name
        ]

        # Client to request robot state
        self.robot_state_client = self.robot.ensure_client(
            RobotStateClient.default_service_name)

        # Client to request local occupancy grid
        self.grid_client = self.robot.ensure_client(
            LocalGridClient.default_service_name)
        self.local_grid_types = self.grid_client.get_local_grid_types()

        # Spot requires a software estop to be activated.
        estop_client = self.robot.ensure_client(
            bosdyn.client.estop.EstopClient.default_service_name)
        self.estop_endpoint = bosdyn.client.estop.EstopEndpoint(
            client=estop_client, name='spot_ros_interface', estop_timeout=9.0)
        self.estop_endpoint.force_simple_setup()

        # Only one client at a time can operate a robot.
        self.lease_client = self.robot.ensure_client(
            bosdyn.client.lease.LeaseClient.default_service_name)
        try:
            self.lease = self.lease_client.acquire()
        except bosdyn.client.lease.ResourceAlreadyClaimedError as err:
            print("ERROR: Lease cannot be acquired. Ensure no other client has the lease. Shutting down.")
            print(err)
            sys.exit()
            
        # True for RViz visualization of Spot in 3rd person with occupancy grid
        self.third_person_view = True

        # Power on motors
        self.motors_on = config.motors_on.lower()!="n"
        # Stairs mode
        self.stair_hint = config.stairs_mode.lower()!="n"


        self.logger = logging.getLogger('rosout')

        self._front_image_requests = []
        for source in front_image_sources:
            self._front_image_requests.append(build_image_request(source, image_format=image_pb2.Image.FORMAT_RAW))
        
        self._front_image_task = AsyncImageService(self.image_client, self.logger, rate=10.0, callback=self.FrontImageCB, image_requests=self._front_image_requests)
        self._async_tasks = AsyncTasks([self._front_image_task])
    
    def updateTasks(self):
        """Loop through all periodic tasks and update their data if needed."""
        try:
            self._async_tasks.update()
        except Exception as e:
            print(f"Update tasks failed with error: {str(e)}")
    
    def getImageMsg(self, data):
        """Takes the imag and  camera data and populates the necessary ROS messages
        Args:
            data: Image proto
            spot_wrapper: A SpotWrapper object
        Returns:
            (tuple):
                * Image: message of the image captured
                * CameraInfo: message to define the state and config of the camera that took the image
        """

        image_msg = sensor_msgs.msg.Image()
        local_time = self.robotToLocalTime(data.shot.acquisition_time)
        image_msg.header.stamp = rospy.Time(local_time.seconds, local_time.nanos)
        image_msg.header.frame_id = data.source.name
        image_msg.height = data.shot.image.rows
        image_msg.width = data.shot.image.cols

        # Color/greyscale formats.
        # JPEG format
        if data.shot.image.format == image_pb2.Image.FORMAT_JPEG:
            image_msg.encoding = "rgb8"
            image_msg.is_bigendian = True
            image_msg.step = 3 * data.shot.image.cols
            image_msg.data = data.shot.image.data

        # Uncompressed.  Requires pixel_format.
        if data.shot.image.format == image_pb2.Image.FORMAT_RAW:
            # One byte per pixel.
            if data.shot.image.pixel_format == image_pb2.Image.PIXEL_FORMAT_GREYSCALE_U8:
                image_msg.encoding = "mono8"
                image_msg.is_bigendian = True
                image_msg.step = data.shot.image.cols
                image_msg.data = data.shot.image.data

            # Three bytes per pixel.
            if data.shot.image.pixel_format == image_pb2.Image.PIXEL_FORMAT_RGB_U8:
                image_msg.encoding = "rgb8"
                image_msg.is_bigendian = True
                image_msg.step = 3 * data.shot.image.cols
                image_msg.data = data.shot.image.data

            # Four bytes per pixel.
            if data.shot.image.pixel_format == image_pb2.Image.PIXEL_FORMAT_RGBA_U8:
                image_msg.encoding = "rgba8"
                image_msg.is_bigendian = True
                image_msg.step = 4 * data.shot.image.cols
                image_msg.data = data.shot.image.data

            # Little-endian uint16 z-distance from camera (mm).
            if data.shot.image.pixel_format == image_pb2.Image.PIXEL_FORMAT_DEPTH_U16:
                image_msg.encoding = "16UC1"
                image_msg.is_bigendian = False
                image_msg.step = 2 * data.shot.image.cols
                image_msg.data = data.shot.image.data

        camera_info_msg = DefaultCameraInfo()
        local_time = self.robotToLocalTime(data.shot.acquisition_time)
        camera_info_msg.header.stamp = rospy.Time(local_time.seconds, local_time.nanos)
        camera_info_msg.header.frame_id = data.source.name
        camera_info_msg.height = data.shot.image.rows
        camera_info_msg.width = data.shot.image.cols

        camera_info_msg.K[0] = data.source.pinhole.intrinsics.focal_length.x
        camera_info_msg.K[2] = data.source.pinhole.intrinsics.principal_point.x
        camera_info_msg.K[4] = data.source.pinhole.intrinsics.focal_length.y
        camera_info_msg.K[5] = data.source.pinhole.intrinsics.principal_point.y

        camera_info_msg.P[0] = data.source.pinhole.intrinsics.focal_length.x
        camera_info_msg.P[2] = data.source.pinhole.intrinsics.principal_point.x
        camera_info_msg.P[5] = data.source.pinhole.intrinsics.focal_length.y
        camera_info_msg.P[6] = data.source.pinhole.intrinsics.principal_point.y

        # Transform from base_link to camera for current img
        body_tform_cam = get_a_tform_b(data.shot.transforms_snapshot,BODY_FRAME_NAME,data.shot.frame_name_image_sensor)
                            
        # Generate camera to body Transform
        body_tform_cam_tf = geometry_msgs.msg.Transform()
        body_tform_cam_tf.translation.x = body_tform_cam.position.x
        body_tform_cam_tf.translation.y = body_tform_cam.position.y
        body_tform_cam_tf.translation.z = body_tform_cam.position.z
        body_tform_cam_tf.rotation.x = body_tform_cam.rotation.x
        body_tform_cam_tf.rotation.y = body_tform_cam.rotation.y
        body_tform_cam_tf.rotation.z = body_tform_cam.rotation.z
        body_tform_cam_tf.rotation.w = body_tform_cam.rotation.w

        camera_transform_stamped_msg = geometry_msgs.msg.TransformStamped()
        local_time = self.robotToLocalTime(data.shot.acquisition_time)
        camera_transform_stamped_msg.header.stamp = rospy.Time(local_time.seconds, local_time.nanos)
        camera_transform_stamped_msg.header.frame_id = "base_link"
        camera_transform_stamped_msg.transform = body_tform_cam_tf
        camera_transform_stamped_msg.child_frame_id = data.source.name

        return image_msg, camera_info_msg, camera_transform_stamped_msg

    def robotToLocalTime(self, timestamp):
        """Takes a timestamp and an estimated skew and return seconds and nano seconds in local time
        Args:
            timestamp: google.protobuf.Timestamp
        Returns:
            google.protobuf.Timestamp
        """

        rtime = Timestamp()

        rtime.seconds = timestamp.seconds - self.time_skew.seconds
        rtime.nanos = timestamp.nanos - self.time_skew.nanos
        if rtime.nanos < 0:
            rtime.nanos = rtime.nanos + 1000000000
            rtime.seconds = rtime.seconds - 1

        # Workaround for timestamps being incomplete
        if rtime.seconds < 0:
            rtime.seconds = 0
            rtime.nanos = 0

        return rtime
    
    @property
    def time_skew(self):
        """Return the time skew between local and spot time"""
        return self.robot.time_sync.endpoint.clock_skew
    
    @property
    def front_images(self):
        """Return latest proto from the _front_image_task"""
        return self._front_image_task.proto


    ### Callback functions ###

    def FrontImageCB(self, results):
        """Callback for when the Spot Wrapper gets new front image data.
        Args:
            results: FutureWrapper object of AsyncPeriodicQuery callback
        """
        data = self.front_images
        if data:
            image_msg0, camera_info_msg0, camera_transform_stamped_msg0 = self.getImageMsg(data[0])
            self.frontleft_image_pub.publish(image_msg0)
            self.frontleft_image_info_pub.publish(camera_info_msg0)
            self.spot_tf_static_broadcaster.sendTransform(camera_transform_stamped_msg0)
            image_msg1, camera_info_msg1, camera_transform_stamped_msg1 = self.getImageMsg(data[1])
            self.frontright_image_pub.publish(image_msg1)
            self.frontright_image_info_pub.publish(camera_info_msg1)
            self.spot_tf_static_broadcaster.sendTransform(camera_transform_stamped_msg1)
            image_msg2, camera_info_msg2, camera_transform_stamped_msg2 = self.getImageMsg(data[2])
            self.frontleft_depth_pub.publish(image_msg2)
            self.frontleft_depth_info_pub.publish(camera_info_msg2)
            self.spot_tf_static_broadcaster.sendTransform(camera_transform_stamped_msg2)
            image_msg3, camera_info_msg3, camera_transform_stamped_msg3 = self.getImageMsg(data[3])
            self.frontright_depth_pub.publish(image_msg3)
            self.frontright_depth_info_pub.publish(camera_info_msg3)
            self.spot_tf_static_broadcaster.sendTransform(camera_transform_stamped_msg3)

    def self_right_cmd_srv(self, stand):
        """ Callback that sends self-right cmd"""
        cmd = RobotCommandBuilder.selfright_command()
        ret = self.command_client.robot_command(cmd)
        rospy.loginfo("Robot self right cmd sent. {}".format(ret))

        return []

    def stand_cmd_srv(self, stand):
        """Callback that sends stand cmd at a given height delta [m] from standard configuration"""

        cmd = RobotCommandBuilder.stand_command(
            body_height=stand.body_pose.translation.z,
            footprint_R_body=self.quat_to_euler(stand.body_pose.rotation)
            )
        ret = self.command_client.robot_command(cmd)
        rospy.loginfo("Robot stand cmd sent. {}".format(ret))

        return []

    @staticmethod
    def seb_trajectory_command(goal_x, goal_y, pose_time, goal_heading, frame_name, params=None, body_height=0.0,
                           locomotion_hint=spot_command_pb2.HINT_AUTO, ):
        """
        Command robot to move to pose along a 2D plane. Pose can be specified in the world
        (kinematic odometry) frame or the robot body frame. The arguments body_height and
        locomotion_hint are ignored if params argument is passed.
        A trajectory command requires an end time. End time is not set in this function, but rather
        is set externally before call to RobotCommandService.
        Args:
            goal_x: Position X coordinate.
            goal_y: Position Y coordinate.
            duration: The duration to reach the point relative to the trajectory reference time.
            goal_heading: Pose heading in radians.
            frame_name: Name of the frame to use.
            params(spot.MobilityParams): Spot specific parameters for mobility commands. If not set,
                this will be constructed using other args.
            body_height: Height, meters, relative to a nominal stand height.
            locomotion_hint: Locomotion hint to use for the trajectory command.
        Returns:
            RobotCommand, which can be issued to the robot command service.
        """
        if not params:
            params = RobotCommandBuilder.mobility_params(body_height=body_height,
                                                         locomotion_hint=locomotion_hint)
        any_params = RobotCommandBuilder._to_any(params)
        position = geometry_pb2.Vec2(x=goal_x, y=goal_y)
        pose = geometry_pb2.SE2Pose(position=position, angle=goal_heading)

        dec, sec = math.modf(pose_time.data)
        duration = google.protobuf.duration_pb2.Duration()
        duration.seconds = int(sec)
        duration.nanos = int(dec*10**9)

        point = trajectory_pb2.SE2TrajectoryPoint(pose=pose, time_since_reference=duration) # Added time_since_reference to set duration
        traj = trajectory_pb2.SE2Trajectory(points=[point], interpolation=1)
        traj_command = basic_command_pb2.SE2TrajectoryCommand.Request(trajectory=traj,
                                                                      se2_frame_name=frame_name)
        mobility_command = mobility_command_pb2.MobilityCommand.Request(
            se2_trajectory_request=traj_command, params=any_params)
        command = robot_command_pb2.RobotCommand(mobility_command=mobility_command)
        
        return command

    # def trajectory_cmd_srv(self, trajectory):
    #     '''
    #     Callback that specifies waypoint(s) (Point) [m] with a final orientation [rad]

    #     The name of the frame that trajectory is relative to.
    #     The trajectory must be expressed in a gravity aligned frame, so either "vision", "odom", or "flat_body".
    #     Any other provided se2_frame_name will be rejected and the trajectory command will not be exectuted.
    #     '''
    #     # TODO: Support other reference frames (currently only VISION ref. frame)

    #     # for waypoints in trajectory.waypoints:
    #     x = trajectory.waypoints.position.x
    #     y = trajectory.waypoints.position.y
    #     # Pose heading (yaw) in radians.
    #     heading = math.atan2(2 * trajectory.waypoints.orientation.z * trajectory.waypoints.orientation.w + 2 * trajectory.waypoints.orientation.x * trajectory.waypoints.orientation.y, 1 - 2 * trajectory.waypoints.orientation.y**2 - 2 * trajectory.waypoints.orientation.z**2)
    #     frame = VISION_FRAME_NAME

    #     prms = RobotCommandBuilder.mobility_params(
    #         body_height=0.0,
    #         locomotion_hint =1,
    #         stair_hint = self.stair_hint
    #     )

    #     cmd = RobotCommandBuilder.trajectory_command(
    #         goal_x=x,
    #         goal_y=y,
    #         goal_heading=heading,
    #         frame_name=frame,
    #         params = prms
    #     )
    #     self.command_client.robot_command(lease=None, command=cmd, end_time_secs=time.time() + self.TRAJECTORY_CMD_TIMEOUT)
            
    #     robot_state = self.get_robot_state()[0].vision_tform_body
    #     final_pose = geometry_msgs.msg.Pose()
    #     final_pose.position = robot_state.translation
    #     final_pose.orientation = robot_state.rotation

    #     # spot_driver.srv.TrajectoryResponse(final_pose)
    #     return final_pose

    def duration_trajectory_cmd_srv(self, trajectory):
        '''
        Callback that specifies waypoint(s) (Point) [m] with a final orientation [rad]

        The name of the frame that trajectory is relative to.
        The trajectory must be expressed in a gravity aligned frame, so either "vision", "odom", or "flat_body".
        Any other provided se2_frame_name will be rejected and the trajectory command will not be exectuted.
        '''
   
        # for waypoints in trajectory.waypoints:
        x = trajectory.waypoints.position.x
        y = trajectory.waypoints.position.y
        time = trajectory.duration
        # Pose heading (yaw) in radians.
        heading = math.atan2(2 * trajectory.waypoints.orientation.z * trajectory.waypoints.orientation.w + 2 * trajectory.waypoints.orientation.x * trajectory.waypoints.orientation.y, 1 - 2 * trajectory.waypoints.orientation.y**2 - 2 * trajectory.waypoints.orientation.z**2)
        frame = VISION_FRAME_NAME

        prms = RobotCommandBuilder.mobility_params(
            body_height=0.0,
            locomotion_hint =1,
            stair_hint = self.stair_hint
        )

        cmd = self.seb_trajectory_command(
            goal_x=x,
            goal_y=y,
            pose_time = time,
            goal_heading=heading,
            frame_name=frame,
            params = prms
        )
        self.command_client.robot_command(lease=None, command=cmd, end_time_secs= rospy.Time.now().to_sec() + self.TRAJECTORY_CMD_TIMEOUT)
            
        robot_state = self.get_robot_state()[0].vision_tform_body
        final_pose = geometry_msgs.msg.Pose()
        final_pose.position = robot_state.translation
        final_pose.orientation = robot_state.rotation

        # spot_driver.srv.TrajectoryResponse(final_pose)
        return final_pose


    def pose_cmd_srv(self, pose):

        robot_state = self.get_robot_state()[0].vision_tform_body
        current_pose = geometry_msgs.msg.Pose()
        current_pose.position = robot_state.translation
        current_pose.orientation = robot_state.rotation

        # current_pose = pose

        return current_pose



    def velocity_cmd_srv(self, twist):
        """Callback that sends instantaneous velocity [m/s] commands to Spot"""
        
        v_x = twist.velocity.linear.x
        v_y = twist.velocity.linear.y
        v_rot = twist.velocity.angular.z

        prms = RobotCommandBuilder.mobility_params(
            body_height=0.0,
            locomotion_hint =1,
            stair_hint = self.stair_hint
        )
        
        cmd = RobotCommandBuilder.velocity_command(
            v_x=v_x,
            v_y=v_y,
            v_rot=v_rot,
            params = prms
        )

        self.command_client.robot_command(
            cmd,
            end_time_secs=time.time() + self.VELOCITY_CMD_DURATION
            # end_time_secs=time.time() + twist.duration.data
        )
        rospy.loginfo(
            "Robot velocity cmd sent: v_x=${},v_y=${},v_rot${}".format(v_x, v_y, v_rot))
        return []

    def stairs_mode_srv(self, rqst):
        """Stairs mode on/off"""
        self.stair_hint = rqst.enable.data
        return []
    
    ### Helper functions ###

    def block_until_pose_reached(self, cmd, goal):
        """Do not return until goal waypoint is reached, or TRAJECTORY_CMD_TIMEOUT is reached."""
        # TODO: Make trajectory_cmd_timeout part of the service request
        
        self.command_client.robot_command(
            cmd,
            end_time_secs = time.time()+self.TRAJECTORY_CMD_TIMEOUT if self.TRAJECTORY_CMD_TIMEOUT else None
        )

        start_time = time.time()
        current_time = time.time()
        while (not self.is_final_state(goal) and (current_time - start_time < self.TRAJECTORY_CMD_TIMEOUT if self.TRAJECTORY_CMD_TIMEOUT else True)):
            time.sleep(.25)
            current_time = time.time()
        return self.is_final_state(goal)

    def is_final_state(self, goal):
        """Check if the current robot state is within range of the specified position."""
        goal_x=goal[0]
        goal_y=goal[1]
        goal_heading=goal[2]
        robot_state = self.get_robot_state()[0].vision_tform_body
        robot_pose = robot_state.translation
        robot_angle = self.quat_to_euler((robot_state.rotation.x, robot_state.rotation.y,
                                          robot_state.rotation.z, robot_state.rotation.w)).yaw

        x_dist = abs(goal_x - robot_pose.x)
        y_dist = abs(goal_y - robot_pose.y)
        angle = abs(goal_heading - robot_angle)
        if ((x_dist < self.x_goal_tolerance) and (y_dist < self.y_goal_tolerance) and (angle < self.angle_goal_tolerance)):
            return True
        return False

    def quat_to_euler(self, quat):
        """Convert a quaternion to xyz Euler angles."""
        q = [quat.x, quat.y, quat.z, quat.w]
        roll = math.atan2(2 * q[3] * q[0] + q[1] * q[2], 1 - 2 * q[0]**2 + 2 * q[1]**2)
        pitch = math.atan2(2 * q[1] * q[3] - 2 * q[0] * q[2], 1 - 2 * q[1]**2 - 2 * q[2]**2)
        yaw = math.atan2(2 * q[2] * q[3] + 2 * q[0] * q[1], 1 - 2 * q[1]**2 - 2 * q[2]**2)
        return bosdyn.geometry.EulerZXY(yaw=yaw, roll=roll, pitch=pitch)

    # TODO: Unit test the get_state method conversion from pbuf to ROS msg (test repeated fields, etc)
    def get_robot_state(self):
        ''' Returns tuple of kinematic_state, robot_state
            kinematic_state:
                timestamp
                joint_states []
                ko_tform_body
                body_twist_rt_ko
                ground_plane_rt_ko
                vo_tform_body
            robot_state:
                power_state
                battery_states[]
                comms_states[]
                system_fault_state
                estop_states[]
                behavior_fault_state
        '''
        robot_state = self.robot_state_client.get_robot_state()
        rs_msg = spot_driver.msg.RobotState()
        
        ''' PowerState conversion '''
        rs_msg.power_state.header.stamp.secs =  robot_state.power_state.timestamp.seconds
        rs_msg.power_state.header.stamp.nsecs =  robot_state.power_state.timestamp.nanos
        rs_msg.power_state.motor_power_state = robot_state.power_state.motor_power_state #[enum]
        rs_msg.power_state.shore_power_state = robot_state.power_state.shore_power_state #[enum]
        rs_msg.power_state.locomotion_charge_percentage = robot_state.power_state.locomotion_charge_percentage.value #[google.protobuf.DoubleValue]
        rs_msg.power_state.locomotion_estimated_runtime.secs = robot_state.power_state.locomotion_estimated_runtime.seconds #[google.protobuf.Duration]

        ''' BatteryState conversion [repeated field] ''' 
        for battery_state in robot_state.battery_states:
            battery_state_msg = sensor_msgs.msg.BatteryState()

            header = std_msgs.msg.Header()
            header.stamp.secs = battery_state.timestamp.seconds
            header.stamp.nsecs = battery_state.timestamp.nanos
            header.frame_id = battery_state.identifier #[string]

            battery_state_msg.header = header

            battery_state_msg.percentage = battery_state.charge_percentage.value/100 #[double]
            # NOTE: Using battery_state_msg.charge as the estimated runtime in sec
            battery_state_msg.charge = battery_state.estimated_runtime.seconds #[google.protobuf.Duration]
            battery_state_msg.current = battery_state.current.value #[DoubleValue]
            battery_state_msg.voltage = battery_state.voltage.value #[DoubleValue]
            # NOTE: Ignoring battery_state.temperatures for now; no field in BatteryState maps directly to it
            battery_state_msg.power_supply_status = battery_state.status #[enum]

            rs_msg.battery_states.append(battery_state_msg)

        ''' CommsState conversion [repeated field] '''
        for comms_state in robot_state.comms_states:
            comms_state_msg = spot_driver.msg.CommsState()

            comms_state_msg.header.stamp.secs = comms_state.timestamp.seconds #[google.protobuf.Timestamp]
            comms_state_msg.header.stamp.nsecs = comms_state.timestamp.nanos #[google.protobuf.Timestamp]
            comms_state_msg.wifi_mode = comms_state.wifi_state.current_mode #[enum] Note: wifi_state is oneof
            comms_state_msg.essid = comms_state.wifi_state.essid #[string]

            rs_msg.comms_states.append(comms_state_msg)

        ''' SystemFaultState conversion '''
        ### faults is Repeated ###
        for fault in robot_state.system_fault_state.faults:
            system_fault_msg = spot_driver.msg.SystemFault()

            system_fault_msg.header.frame_id = fault.name #[string]
            system_fault_msg.header.stamp.secs = fault.onset_timestamp.seconds #[google.protobuf.Timestamp]
            system_fault_msg.header.stamp.nsecs = fault.onset_timestamp.nanos #[google.protobuf.Timestamp]
            system_fault_msg.duration.secs = fault.duration.seconds #[google.protobuf.Duration]
            system_fault_msg.duration.nsecs = fault.duration.nanos #[google.protobuf.Duration]
            system_fault_msg.code = fault.code #[int32]
            system_fault_msg.uid =  fault.uid #[uint64]
            system_fault_msg.error_message = fault.error_message #[string]
            system_fault_msg.attributes = fault.attributes #[repeated-string]
            system_fault_msg.severity = fault.severity #[enum]

            rs_msg.system_fault_state.faults.append(system_fault_msg)

        ### historical_faults is Repeated ###
        for historical_fault in robot_state.system_fault_state.faults:
            system_fault_msg = spot_driver.msg.SystemFault()

            system_fault_msg.header.frame_id = historical_fault.name #[string]
            system_fault_msg.header.stamp.secs = historical_fault.onset_timestamp.seconds #[google.protobuf.Timestamp]
            system_fault_msg.header.stamp.nsecs = historical_fault.onset_timestamp.nanos #[google.protobuf.Timestamp]
            system_fault_msg.duration.secs = historical_fault.duration.seconds #[google.protobuf.Duration]
            system_fault_msg.duration.nsecs = historical_fault.duration.nanos #[google.protobuf.Duration]
            system_fault_msg.code = historical_fault.code #[int32]
            system_fault_msg.uid =  historical_fault.uid #[uint64]
            system_fault_msg.error_message = historical_fault.error_message #[string]
            system_fault_msg.attributes = historical_fault.attributes #[repeated-string]
            system_fault_msg.severity = historical_fault.severity #[enum]

            rs_msg.system_fault_state.historical_faults.append(system_fault_msg)

        #[map<string,enum>]
        if robot_state.system_fault_state.aggregated:
            for key, value in robot_state.system_fault_state.aggregated.items():
                kv = diagnostic_msgs.msg.KeyValue()
                kv.key = key
                kv.value = value
                rs_msg.system_fault_state.aggregated.append(kv)

        ''' EStopState conversion [repeated field] '''
        for estop_state in robot_state.estop_states:
            estop_msg = spot_driver.msg.EStopState()

            estop_msg.header.stamp.secs = estop_state.timestamp.seconds #[google.protobuf.Timestamp]
            estop_msg.header.stamp.nsecs = estop_state.timestamp.nanos #[google.protobuf.Timestamp]
            estop_msg.header.frame_id = estop_state.name #[string]
            estop_msg.type = estop_state.type #[enum]
            estop_msg.state = estop_state.state #[enum]
            estop_msg.state_description = estop_state.state_description #[string]

            rs_msg.estop_states.append(estop_msg)

        ''' KinematicState conversion '''
        ks_msg = spot_driver.msg.KinematicState()

        ks_msg.header.stamp.secs = robot_state.kinematic_state.acquisition_timestamp.seconds
        ks_msg.header.stamp.nsecs = robot_state.kinematic_state.acquisition_timestamp.nanos

        joint_dict = {"fl.hx": "front_left_hip_x", "fl.hy": "front_left_hip_y", "fl.kn": "front_left_knee", "fr.hx": "front_right_hip_x", 
        "fr.hy": "front_right_hip_y", "fr.kn": "front_right_knee", "hl.hx": "rear_left_hip_x", "hl.hy": "rear_left_hip_y", "hl.kn": "rear_left_knee", 
        "hr.hx": "rear_right_hip_x", "hr.hy": "rear_right_hip_y", "hr.kn": "rear_right_knee"}

        ### joint_states is repeated ###
        js = sensor_msgs.msg.JointState()
        js.header.stamp = ks_msg.header.stamp
        for joint_state in robot_state.kinematic_state.joint_states:
            js.name.append(joint_dict[joint_state.name]) # [string]
            js.position.append(joint_state.position.value) # Note: angle in rad
            js.velocity.append(joint_state.velocity.value) # Note: ang vel
            # NOTE: ang accel. JointState doesn't have accel. Ignoring joint_state.acceleration for now.
            js.effort.append(joint_state.load.value) # Note: Torque in N-m

        ks_msg.joint_states = js

        # SE3Pose representing transform of Spot's Body frame relative to the inertial Vision frame
        vision_tform_body = get_vision_tform_body(robot_state.kinematic_state.transforms_snapshot)

        ks_msg.vision_tform_body.translation.x = vision_tform_body.x
        ks_msg.vision_tform_body.translation.y = vision_tform_body.y
        ks_msg.vision_tform_body.translation.z = vision_tform_body.z

        ks_msg.vision_tform_body.rotation.x = vision_tform_body.rot.x
        ks_msg.vision_tform_body.rotation.y = vision_tform_body.rot.y
        ks_msg.vision_tform_body.rotation.z = vision_tform_body.rot.z
        ks_msg.vision_tform_body.rotation.w = vision_tform_body.rot.w

        # odom_tform_body: SE3Pose representing transform of Spot's Body frame relative to the odometry frame
        odom_tform_body = get_odom_tform_body(robot_state.kinematic_state.transforms_snapshot)

        ks_msg.odom_tform_body.translation.x = odom_tform_body.x
        ks_msg.odom_tform_body.translation.y = odom_tform_body.y
        ks_msg.odom_tform_body.translation.z = odom_tform_body.z

        ks_msg.odom_tform_body.rotation.x = odom_tform_body.rot.x
        ks_msg.odom_tform_body.rotation.y = odom_tform_body.rot.y
        ks_msg.odom_tform_body.rotation.z = odom_tform_body.rot.z
        ks_msg.odom_tform_body.rotation.w = odom_tform_body.rot.w

        ''' velocity_of_body_in_vision '''
        ks_msg.velocity_of_body_in_vision.linear.x = robot_state.kinematic_state.velocity_of_body_in_vision.linear.x
        ks_msg.velocity_of_body_in_vision.linear.y = robot_state.kinematic_state.velocity_of_body_in_vision.linear.y
        ks_msg.velocity_of_body_in_vision.linear.z = robot_state.kinematic_state.velocity_of_body_in_vision.linear.z

        ks_msg.velocity_of_body_in_vision.angular.x = robot_state.kinematic_state.velocity_of_body_in_vision.angular.x
        ks_msg.velocity_of_body_in_vision.angular.y = robot_state.kinematic_state.velocity_of_body_in_vision.angular.y
        ks_msg.velocity_of_body_in_vision.angular.z = robot_state.kinematic_state.velocity_of_body_in_vision.angular.z

        ''' velocity_of_body_in_odom '''

        ks_msg.velocity_of_body_in_odom.linear.x = robot_state.kinematic_state.velocity_of_body_in_odom.linear.x
        ks_msg.velocity_of_body_in_odom.linear.y = robot_state.kinematic_state.velocity_of_body_in_odom.linear.y
        ks_msg.velocity_of_body_in_odom.linear.z = robot_state.kinematic_state.velocity_of_body_in_odom.linear.z

        ks_msg.velocity_of_body_in_odom.angular.x = robot_state.kinematic_state.velocity_of_body_in_odom.angular.x
        ks_msg.velocity_of_body_in_odom.angular.y = robot_state.kinematic_state.velocity_of_body_in_odom.angular.y
        ks_msg.velocity_of_body_in_odom.angular.z = robot_state.kinematic_state.velocity_of_body_in_odom.angular.z


        ### BehaviorFaultState conversion
        '''faults is repeated'''
        for fault in robot_state.behavior_fault_state.faults:
            behaviour_fault_state_msg = spot_driver.msg.BehaviorFaultState()

            behaviour_fault_state_msg.header.frame_id = fault.behavior_fault_id #[uint32]
            behaviour_fault_state_msg.header.stamp.secs = fault.onset_timestamp.seconds #[google.protobuf.Timestamp]
            behaviour_fault_state_msg.header.stamp.nsecs = fault.onset_timestamp.nanos #[google.protobuf.Timestamp]
            behaviour_fault_state_msg.cause = fault.cause #[enum]
            behaviour_fault_state_msg.status = fault.status #[enum]

            rs_msg.behavior_fault_states.append(behaviour_fault_state_msg)

        ### FootState conversion [repeated]
        for foot_state in robot_state.foot_state:
            foot_state_msg = spot_driver.msg.FootState()

            foot_state_msg.foot_position_rt_body.x = foot_state.foot_position_rt_body.x #[double]
            foot_state_msg.foot_position_rt_body.y = foot_state.foot_position_rt_body.y #[double]
            foot_state_msg.foot_position_rt_body.z = foot_state.foot_position_rt_body.z #[double]
            foot_state_msg.contact = foot_state.contact #[enum]

            rs_msg.foot_states.append(foot_state_msg)
        

        return ks_msg, rs_msg  #kinematic state message, robot state message
    

    def start_spot_ros_interface(self):

        # ROS Node initialization
        rospy.init_node('spot_ros_interface_py')
        rate = rospy.Rate(200)  # Update at 200 Hz

        # Each service will handle a specific command to Spot instance
        rospy.Service("self_right_cmd", spot_driver.srv.Stand, self.self_right_cmd_srv)
        rospy.Service("stand_cmd", spot_driver.srv.Stand, self.stand_cmd_srv)
        # rospy.Service("trajectory_cmd", spot_driver.srv.Trajectory, self.trajectory_cmd_srv)
        rospy.Service("duration_trajectory_cmd", spot_driver.srv.Trajectory_duration, self.duration_trajectory_cmd_srv)
        rospy.Service("velocity_cmd", spot_driver.srv.Velocity, self.velocity_cmd_srv)
        rospy.Service("stairs_mode", spot_driver.srv.Stairs, self.stairs_mode_srv)
        rospy.Service("pose_cmd", spot_driver.srv.GetPose, self.pose_cmd_srv)

        # Single image publisher will publish all images from all Spot cameras
        kinematic_state_pub = rospy.Publisher(
            "kinematic_state", spot_driver.msg.KinematicState, queue_size=20)
        robot_state_pub = rospy.Publisher(
            "robot_state", spot_driver.msg.RobotState, queue_size=20)
        occupancy_grid_pub = rospy.Publisher(
            "occupancy_grid", visualization_msgs.msg.Marker, queue_size=20)

        # Publish tf2 from visual odometry frame to Spot's base link
        spot_tf_broadcaster = tf2_ros.TransformBroadcaster()

        # Publish static tf2 from Spot's base link to front-left camera
        self.spot_tf_static_broadcaster = tf2_ros.StaticTransformBroadcaster()

        # Images #
        self.frontleft_image_pub = rospy.Publisher('camera/frontleft/image', sensor_msgs.msg.Image, queue_size=10)
        self.frontright_image_pub = rospy.Publisher('camera/frontright/image', sensor_msgs.msg.Image, queue_size=10)
        # Depth #
        self.frontleft_depth_pub = rospy.Publisher('depth/frontleft/image', sensor_msgs.msg.Image, queue_size=10)
        self.frontright_depth_pub = rospy.Publisher('depth/frontright/image', sensor_msgs.msg.Image, queue_size=10)

        # Image Camera Info #
        self.frontleft_image_info_pub = rospy.Publisher('camera/frontleft/camera_info', sensor_msgs.msg.CameraInfo, queue_size=10)
        self.frontright_image_info_pub = rospy.Publisher('camera/frontright/camera_info', sensor_msgs.msg.CameraInfo, queue_size=10)
        # Depth Camera Info #
        self.frontleft_depth_info_pub = rospy.Publisher('depth/frontleft/camera_info', sensor_msgs.msg.CameraInfo, queue_size=10)
        self.frontright_depth_info_pub = rospy.Publisher('depth/frontright/camera_info', sensor_msgs.msg.CameraInfo, queue_size=10)

        # For RViz 3rd person POV visualization
        if self.third_person_view:
            joint_state_pub = rospy.Publisher(
                "joint_state_from_spot", sensor_msgs.msg.JointState, queue_size=20)

        try:
            with bosdyn.client.lease.LeaseKeepAlive(self.lease_client), bosdyn.client.estop.EstopKeepAlive(
                    self.estop_endpoint):
                rospy.loginfo("Acquired lease")
                if self.motors_on:
                    rospy.loginfo("Powering on robot... This may take a several seconds.")
                    self.robot.power_on(timeout_sec=20)
                    assert self.robot.is_powered_on(), "Robot power on failed."
                    rospy.loginfo("Robot powered on.")
                else:
                    rospy.loginfo("Not powering on robot, continuing")

                while not rospy.is_shutdown():
                    ''' Publish Robot State'''
                    kinematic_state, robot_state = self.get_robot_state()

                    kinematic_state_pub.publish(kinematic_state)
                    robot_state_pub.publish(robot_state)
                    
                    # Publish tf2 from the fixed vision_odometry_frame to the Spot's base_link
                    t = geometry_msgs.msg.TransformStamped()
                    t.header.stamp = rospy.Time.now()
                    t.header.frame_id = "vision_odometry_frame"
                    t.child_frame_id = "base_link"
                    t.transform.translation.x = kinematic_state.vision_tform_body.translation.x
                    t.transform.translation.y = kinematic_state.vision_tform_body.translation.y
                    t.transform.translation.z = kinematic_state.vision_tform_body.translation.z
                    t.transform.rotation.x = kinematic_state.vision_tform_body.rotation.x
                    t.transform.rotation.y = kinematic_state.vision_tform_body.rotation.y
                    t.transform.rotation.z = kinematic_state.vision_tform_body.rotation.z
                    t.transform.rotation.w = kinematic_state.vision_tform_body.rotation.w
                    spot_tf_broadcaster.sendTransform(t)

                    if self.third_person_view:
                        joint_state_pub.publish(kinematic_state.joint_states)

                    ''' Publish Images'''
                    self.updateTasks()
                    
                    ''' Publish occupancy grid'''
                    if occupancy_grid_pub.get_num_connections() > 0:
                        local_grid_proto = self.grid_client.get_local_grids(['terrain'])
                        markers = get_terrain_markers(local_grid_proto)
                        occupancy_grid_pub.publish(markers)

                    rospy.logdebug("Looping...")
                    rate.sleep()

        finally:
            # If we successfully acquired a lease, return it.
            self.lease_client.return_lease(self.lease)

if __name__ == '__main__':
    """Command line interface."""
    parser = argparse.ArgumentParser()
    bosdyn.client.util.add_common_arguments(parser)
    parser.add_argument('--motors_on', help='Power on motors [Y/n]', default="Y")
    parser.add_argument('--stairs_mode', help='Stairs mode [Y/n]', default="n")
    options, unknown = parser.parse_known_args(sys.argv[1:])
    print(unknown)

    try:
        robot = SpotInterface(options)
        robot.start_spot_ros_interface()
    except rospy.ROSInterruptException:
        pass
